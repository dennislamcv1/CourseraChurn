{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Tree Classification Template\n",
    "\n",
    "## Notebook for Decision Tree/Random Forest/Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will be tackling the churn prediction problem on a very unique and interesting group of subscribers on a video streaming service! \n",
    "\n",
    "Imagine that you are a new data scientist at this video streaming company and you are tasked with building a model that can predict which existing subscribers will continue their subscriptions for another month. We have provided a dataset that is a sample of subscriptions that were initiated in 2021, all snapshotted at a particular date before the subscription was cancelled. Subscription cancellation can happen for a multitude of reasons, including:\n",
    "* the customer completes all content they were interested in, and no longer need the subscription\n",
    "* the customer finds themselves to be too busy and cancels their subscription until a later time\n",
    "* the customer determines that the streaming service is not the best fit for them, so they cancel and look for something better suited\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tasks\n",
    "\n",
    "### 1) Understand the shape of the data (Histograms, box plots, etc.)\n",
    "\n",
    "### 2) Data Cleaning \n",
    "\n",
    "### 3) Data Exploration\n",
    "\n",
    "### 4) Feature Engineering \n",
    "\n",
    "### 5) Data Preprocessing for Model\n",
    "\n",
    "### 6) Basic Model Building \n",
    "\n",
    "### 7) Model Tuning \n",
    "\n",
    "### 8) Ensemble Model Building \n",
    "\n",
    "### 9) Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero, median, mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler, Binarizer, OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "\n",
    "# from sklearn.feature_selection import f_classif, chi2, RFE, RFECV\n",
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "# from sklearn.feature_selection import VarianceThreshold, GenericUnivariateSelect\n",
    "# from sklearn.feature_selection import SelectFromModel, SelectKBest, SelectPercentile\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "\n",
    "import feature_engine\n",
    "\n",
    "from feature_engine.selection import (DropConstantFeatures, DropDuplicateFeatures, \n",
    "                                      DropCorrelatedFeatures, SmartCorrelatedSelection)\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance, SelectByShuffling, RecursiveFeatureElimination\n",
    "from feature_engine.selection import RecursiveFeatureAddition\n",
    "\n",
    "#import imblearn\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib inline\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60 \n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "font = {'family' : 'monospace',\n",
    "          'weight' : 'bold',\n",
    "          'size'   : '20'}\n",
    "plt.rc('font' , **font)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import pickle\n",
    "# from pickle import dump, load\n",
    "\n",
    "\n",
    "# PyCaret\n",
    "from pycaret.classification import *\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Ensure results are reproducible\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_descriptions = pd.read_csv('data_descriptions.csv')\n",
    "data_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quick Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "df.describe(include=[\"int\", \"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "df['churn'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountage</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>subscriptiontype</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>contenttype</th>\n",
       "      <th>multideviceaccess</th>\n",
       "      <th>deviceregistered</th>\n",
       "      <th>viewinghoursperweek</th>\n",
       "      <th>averageviewingduration</th>\n",
       "      <th>contentdownloadspermonth</th>\n",
       "      <th>genrepreference</th>\n",
       "      <th>userrating</th>\n",
       "      <th>supportticketspermonth</th>\n",
       "      <th>gender</th>\n",
       "      <th>watchlistsize</th>\n",
       "      <th>parentalcontrol</th>\n",
       "      <th>subtitlesenabled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>17.87</td>\n",
       "      <td>679.04</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>29.13</td>\n",
       "      <td>122.27</td>\n",
       "      <td>42</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>9.91</td>\n",
       "      <td>763.29</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>36.87</td>\n",
       "      <td>57.09</td>\n",
       "      <td>43</td>\n",
       "      <td>Action</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15.02</td>\n",
       "      <td>75.10</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Computer</td>\n",
       "      <td>7.60</td>\n",
       "      <td>140.41</td>\n",
       "      <td>14</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4.81</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>15.36</td>\n",
       "      <td>1351.45</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>35.59</td>\n",
       "      <td>177.00</td>\n",
       "      <td>14</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4.94</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>12.41</td>\n",
       "      <td>1128.95</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>23.50</td>\n",
       "      <td>70.31</td>\n",
       "      <td>6</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountage  monthlycharges  totalcharges subscriptiontype     paymentmethod paperlessbilling contenttype multideviceaccess deviceregistered  viewinghoursperweek  averageviewingduration  contentdownloadspermonth genrepreference  userrating  supportticketspermonth  gender  watchlistsize parentalcontrol subtitlesenabled\n",
       "0          38           17.87        679.04          Premium      Mailed check               No    TV Shows                No               TV                29.13                  122.27                        42          Comedy        3.52                       2    Male             23              No               No\n",
       "1          77            9.91        763.29            Basic  Electronic check              Yes    TV Shows                No               TV                36.87                   57.09                        43          Action        2.02                       2  Female             22             Yes               No\n",
       "2           5           15.02         75.10         Standard     Bank transfer               No    TV Shows               Yes         Computer                 7.60                  140.41                        14          Sci-Fi        4.81                       2  Female             22              No              Yes\n",
       "3          88           15.36       1351.45         Standard  Electronic check               No        Both               Yes           Tablet                35.59                  177.00                        14          Comedy        4.94                       0  Female             23             Yes              Yes\n",
       "4          91           12.41       1128.95         Standard       Credit card              Yes    TV Shows               Yes           Tablet                23.50                   70.31                         6           Drama        2.85                       6  Female              0              No               No"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountage</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>viewinghoursperweek</th>\n",
       "      <th>averageviewingduration</th>\n",
       "      <th>contentdownloadspermonth</th>\n",
       "      <th>userrating</th>\n",
       "      <th>supportticketspermonth</th>\n",
       "      <th>watchlistsize</th>\n",
       "      <th>subscriptiontype_Basic</th>\n",
       "      <th>subscriptiontype_Premium</th>\n",
       "      <th>subscriptiontype_Standard</th>\n",
       "      <th>paymentmethod_Bank transfer</th>\n",
       "      <th>paymentmethod_Credit card</th>\n",
       "      <th>paymentmethod_Electronic check</th>\n",
       "      <th>paymentmethod_Mailed check</th>\n",
       "      <th>paperlessbilling_Yes</th>\n",
       "      <th>contenttype_Both</th>\n",
       "      <th>contenttype_Movies</th>\n",
       "      <th>contenttype_TV Shows</th>\n",
       "      <th>multideviceaccess_Yes</th>\n",
       "      <th>deviceregistered_Computer</th>\n",
       "      <th>deviceregistered_Mobile</th>\n",
       "      <th>deviceregistered_TV</th>\n",
       "      <th>deviceregistered_Tablet</th>\n",
       "      <th>genrepreference_Action</th>\n",
       "      <th>genrepreference_Comedy</th>\n",
       "      <th>genrepreference_Drama</th>\n",
       "      <th>genrepreference_Fantasy</th>\n",
       "      <th>genrepreference_Sci-Fi</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>parentalcontrol_Yes</th>\n",
       "      <th>subtitlesenabled_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104475</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104476</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104477</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104478</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104479</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104480 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        accountage  monthlycharges  totalcharges  viewinghoursperweek  averageviewingduration  contentdownloadspermonth  userrating  supportticketspermonth  watchlistsize  subscriptiontype_Basic  subscriptiontype_Premium  subscriptiontype_Standard  paymentmethod_Bank transfer  paymentmethod_Credit card  paymentmethod_Electronic check  paymentmethod_Mailed check  paperlessbilling_Yes  contenttype_Both  contenttype_Movies  contenttype_TV Shows  multideviceaccess_Yes  deviceregistered_Computer  deviceregistered_Mobile  deviceregistered_TV  deviceregistered_Tablet  genrepreference_Action  genrepreference_Comedy  genrepreference_Drama  genrepreference_Fantasy  genrepreference_Sci-Fi  gender_Male  parentalcontrol_Yes  subtitlesenabled_Yes\n",
       "0             0.31            0.86          0.28                 0.72                    0.67                      0.86        0.63                    0.22           0.96                    0.00                      1.00                       0.00                         0.00                       0.00                            0.00                        1.00                  0.00              0.00                0.00                  1.00                   0.00                       0.00                     0.00                 1.00                     0.00                    0.00                    1.00                   0.00                     0.00                    0.00         1.00                 0.00                  0.00\n",
       "1             0.64            0.33          0.32                 0.92                    0.30                      0.88        0.26                    0.22           0.92                    1.00                      0.00                       0.00                         0.00                       0.00                            1.00                        0.00                  1.00              0.00                0.00                  1.00                   0.00                       0.00                     0.00                 1.00                     0.00                    1.00                    0.00                   0.00                     0.00                    0.00         0.00                 1.00                  0.00\n",
       "2             0.03            0.67          0.03                 0.17                    0.77                      0.29        0.95                    0.22           0.92                    0.00                      0.00                       1.00                         1.00                       0.00                            0.00                        0.00                  0.00              0.00                0.00                  1.00                   1.00                       1.00                     0.00                 0.00                     0.00                    0.00                    0.00                   0.00                     0.00                    1.00         0.00                 0.00                  1.00\n",
       "3             0.74            0.69          0.57                 0.89                    0.98                      0.29        0.99                    0.00           0.96                    0.00                      0.00                       1.00                         0.00                       0.00                            1.00                        0.00                  0.00              1.00                0.00                  0.00                   1.00                       0.00                     0.00                 0.00                     1.00                    0.00                    1.00                   0.00                     0.00                    0.00         0.00                 1.00                  1.00\n",
       "4             0.76            0.49          0.47                 0.58                    0.37                      0.12        0.46                    0.67           0.00                    0.00                      0.00                       1.00                         0.00                       1.00                            0.00                        0.00                  1.00              0.00                0.00                  1.00                   1.00                       0.00                     0.00                 0.00                     1.00                    0.00                    0.00                   1.00                     0.00                    0.00         0.00                 0.00                  0.00\n",
       "...            ...             ...           ...                  ...                     ...                       ...         ...                     ...            ...                     ...                       ...                        ...                          ...                        ...                             ...                         ...                   ...               ...                 ...                   ...                    ...                        ...                      ...                  ...                      ...                     ...                     ...                    ...                      ...                     ...          ...                  ...                   ...\n",
       "104475        0.67            0.82          0.58                 0.47                    0.75                      0.71        0.10                    0.78           0.58                    0.00                      0.00                       1.00                         0.00                       1.00                            0.00                        0.00                  0.00              0.00                0.00                  1.00                   1.00                       0.00                     1.00                 0.00                     0.00                    0.00                    1.00                   0.00                     0.00                    0.00         0.00                 0.00                  1.00\n",
       "104476        0.16            0.22          0.07                 0.77                    0.63                      0.35        0.45                    0.22           0.33                    0.00                      1.00                       0.00                         1.00                       0.00                            0.00                        0.00                  1.00              0.00                1.00                  0.00                   1.00                       0.00                     1.00                 0.00                     0.00                    0.00                    0.00                   1.00                     0.00                    0.00         1.00                 1.00                  0.00\n",
       "104477        0.89            0.88          0.81                 0.16                    0.60                      0.63        0.50                    0.11           0.50                    1.00                      0.00                       0.00                         0.00                       0.00                            0.00                        1.00                  0.00              0.00                1.00                  0.00                   1.00                       1.00                     0.00                 0.00                     0.00                    0.00                    1.00                   0.00                     0.00                    0.00         1.00                 0.00                  1.00\n",
       "104478        0.38            0.99          0.38                 0.64                    0.63                      0.02        1.00                    0.00           0.50                    1.00                      0.00                       0.00                         1.00                       0.00                            0.00                        0.00                  0.00              0.00                0.00                  1.00                   1.00                       0.00                     0.00                 1.00                     0.00                    0.00                    0.00                   1.00                     0.00                    0.00         0.00                 1.00                  0.00\n",
       "104479        0.92            0.16          0.34                 0.85                    0.73                      0.59        0.92                    0.22           0.29                    1.00                      0.00                       0.00                         1.00                       0.00                            0.00                        0.00                  1.00              1.00                0.00                  0.00                   0.00                       1.00                     0.00                 0.00                     0.00                    0.00                    0.00                   1.00                     0.00                    0.00         0.00                 0.00                  1.00\n",
       "\n",
       "[104480 rows x 33 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.transform(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = preprocessor.transform(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.corr(),cmap=\"coolwarm\",annot=True,fmt='.2f',linewidths=2)\n",
    "plt.title(\"Correlation Heatmap\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountage</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>subscriptiontype</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>contenttype</th>\n",
       "      <th>multideviceaccess</th>\n",
       "      <th>deviceregistered</th>\n",
       "      <th>viewinghoursperweek</th>\n",
       "      <th>averageviewingduration</th>\n",
       "      <th>contentdownloadspermonth</th>\n",
       "      <th>genrepreference</th>\n",
       "      <th>userrating</th>\n",
       "      <th>supportticketspermonth</th>\n",
       "      <th>gender</th>\n",
       "      <th>watchlistsize</th>\n",
       "      <th>parentalcontrol</th>\n",
       "      <th>subtitlesenabled</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>19.71</td>\n",
       "      <td>256.26</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>No</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>6.48</td>\n",
       "      <td>50.03</td>\n",
       "      <td>33</td>\n",
       "      <td>Action</td>\n",
       "      <td>1.18</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>9.25</td>\n",
       "      <td>527.13</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>No</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>17.04</td>\n",
       "      <td>44.53</td>\n",
       "      <td>14</td>\n",
       "      <td>Action</td>\n",
       "      <td>4.57</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>9.36</td>\n",
       "      <td>926.48</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Computer</td>\n",
       "      <td>14.30</td>\n",
       "      <td>43.81</td>\n",
       "      <td>31</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>13.17</td>\n",
       "      <td>368.90</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Movies</td>\n",
       "      <td>No</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>6.88</td>\n",
       "      <td>57.23</td>\n",
       "      <td>49</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>18.95</td>\n",
       "      <td>132.63</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Both</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>27.01</td>\n",
       "      <td>95.18</td>\n",
       "      <td>44</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountage  monthlycharges  totalcharges subscriptiontype  paymentmethod paperlessbilling contenttype multideviceaccess deviceregistered  viewinghoursperweek  averageviewingduration  contentdownloadspermonth genrepreference  userrating  supportticketspermonth  gender  watchlistsize parentalcontrol subtitlesenabled  churn\n",
       "0          13           19.71        256.26            Basic    Credit card               No        Both                No           Tablet                 6.48                   50.03                        33          Action        1.18                       6    Male              7             Yes               No      0\n",
       "1          57            9.25        527.13          Premium  Bank transfer               No        Both                No           Mobile                17.04                   44.53                        14          Action        4.57                       8    Male              7             Yes              Yes      0\n",
       "2          99            9.36        926.48            Basic  Bank transfer               No        Both               Yes         Computer                14.30                   43.81                        31         Fantasy        1.95                       0    Male             17              No               No      0\n",
       "3          28           13.17        368.90            Basic   Mailed check              Yes      Movies                No           Mobile                 6.88                   57.23                        49           Drama        1.41                       2  Female              7             Yes              Yes      0\n",
       "4           7           18.95        132.63         Standard  Bank transfer              Yes        Both               Yes           Tablet                27.01                   95.18                        44         Fantasy        3.99                       7  Female             11             Yes               No      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24379, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:19]\n",
    "y = df.iloc[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[13, 19.71252476, 256.2628218, ..., 7, 'Yes', 'No'],\n",
       "        [57, 9.247976928, 527.1346849, ..., 7, 'Yes', 'Yes'],\n",
       "        [99, 9.358378775, 926.4794987, ..., 17, 'No', 'No'],\n",
       "        ...,\n",
       "        [90, 19.65641069, 1769.076962, ..., 20, 'Yes', 'Yes'],\n",
       "        [100, 11.94102383, 1194.102383, ..., 9, 'Yes', 'No'],\n",
       "        [82, 15.87585614, 1301.820204, ..., 24, 'No', 'Yes']], dtype=object),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19503, 19), (4876, 19), (19503,), (4876,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 15992, 1: 3511})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipelines\n",
    "\n",
    "Data Pipelines simplify the steps of processing the data. We use the module <code>Pipeline</code> to create a pipeline. \n",
    "`Pipeline` lets you chain together multiple operators on your data that both have a `fit` method.\n",
    "\n",
    "### Combine multiple processing steps into a `Pipeline`\n",
    "\n",
    "A pipeline contains a series of steps, where a step is (\"name of step\", actual_model). The \"name of step\" string is only used to help you identify which step you are on, and to allow you to specify parameters at that step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare preprocessing functions\n",
    "\n",
    "#imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#ohe = OneHotEncoder()\n",
    "#oe = OrdinalEncoder()\n",
    "#ss = StandardScaler()\n",
    "#mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.select_dtypes(include=[\"int64\",\"float64\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.select_dtypes(include=[\"bool\",\"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = ['accountage', 'monthlycharges', 'totalcharges', 'viewinghoursperweek', 'averageviewingduration',\n",
    " 'contentdownloadspermonth', 'userrating', 'supportticketspermonth', 'watchlistsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = ['subscriptiontype', 'paymentmethod', 'paperlessbilling', 'contenttype', 'multideviceaccess',\n",
    " 'deviceregistered', 'genrepreference', 'gender', 'parentalcontrol', 'subtitlesenabled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both\n",
    "# numerical and categorical data\n",
    "\n",
    "\n",
    "drop_transformer = ColumnTransformer(transformers=\n",
    "                                    (\"dropcolumns\", \"drop\", [])\n",
    "                                    )\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "                             # (\"scalar\", StandardScaler()),\n",
    "                              (\"minmax\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "                                  (\"onehot\", OneHotEncoder(sparse_output=False, drop='if_binary')),\n",
    "    \n",
    "                                  #(\"ordinal\", OrdinalEncoder(categories='auto', handle_unknown=\"error\"))\n",
    "   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "               transformers=[\n",
    "                           #(\"dropcolumns\", \"drop\", [\"id\"]),\n",
    "                           (\"numerical\", numeric_transformer, numcols),\n",
    "                           (\"categorical\", categorical_transformer, catcols),\n",
    "                   \n",
    "                            ],\n",
    "               remainder=\"passthrough\",\n",
    "               verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "               transformers=[\n",
    "                           (\"dropcolumns\", \"drop\", [\"id\"]),\n",
    "                           (\"numerical\", numeric_transformer, numcols),\n",
    "                           #(\"categorical\", categorical_transformer, catcols),\n",
    "                   \n",
    "                            ],\n",
    "               remainder=\"drop\",\n",
    "               verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features transformation (Train Set)\n",
    "\n",
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features transformation (Test Set)\n",
    "\n",
    "preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessor.fit_transform(X_train)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model (Baseline)\n",
    "\n",
    "The `DecisionTreeClassifier` has many arguments (model hyperparameters) that can be customized and eventually tune the generated decision tree classifiers. Among these arguments, there are three commonly tuned arguments as follows:\n",
    "- criterion: `gini` or `entropy`, which specifies which criteria to be used when splitting a tree node\n",
    "- max_depth: a numeric value to specify the max depth of the tree. Larger tree depth normally means larger model complexity\n",
    "- min_samples_leaf: The minimal number of samples in leaf nodes. Larger samples in leaf nodes will tend to generate simpler trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpipeline = Pipeline(steps=[\n",
    "                        (\"preprocessor\", preprocessor),\n",
    "                        (\"decisiontree\", DecisionTreeClassifier(random_state=0))\n",
    "                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpred = dtpipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the second column of probabilities (class 1) and rename it\n",
    "dt_predicted_probability = dtpred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Classifier\\n\")\n",
    "print('Accuracy:', '%.3f' % accuracy_score(y_test, dt_predicted_probability))\n",
    "print('Precision:', '%.3f' % precision_score(y_test, dt_predicted_probability))\n",
    "print('Recall:', '%.3f' % recall_score(y_test, dt_predicted_probability))\n",
    "print('F1 Score:', '%.3f' % f1_score(y_test, dt_predicted_probability))\n",
    "print('AUC score:', '%3.f' % roc_auc_score(y_test, dt_predicted_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_predicted_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcm = confusion_matrix(y_test, dt_predicted_probability)\n",
    "dtcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=dtpipeline, X=X_test, y=y_test, ax=ax, \n",
    "                                      labels=dtpipeline.classes_, cmap=\"viridis\")\n",
    "\n",
    "ax.set_title('Confusion matrix of the classifier', size=20)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=dtpipeline, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "#ax.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(estimator=dtpipeline, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('Precision/Recall of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv = cross_validate(estimator=dtpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=skf, n_jobs=2, return_train_score=True)\n",
    "dtcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcv[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = cross_val_score(estimator=dtpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=skf, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpipeline.named_steps.decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plot_tree(dtpipeline.named_steps.decisiontree, max_depth=2, feature_names=X.columns, class_names=['0','1'], fontsize=14, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dtpipeline.named_steps.decisiontree.feature_importances_\n",
    "\n",
    "feature_importances = pd.Series(importances, index=X.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "feature_importances.plot.bar(ax=ax, figsize=(10,5))\n",
    "ax.set_title(\"Decision Tree Feature Importances\")\n",
    "ax.tick_params('x', rotation=30)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df = pd.DataFrame(feature_importances, columns=[\"importances\"])\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importances')\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.barplot(data=feature_importances_df, x=feature_importances_df.importances, y=feature_importances_df.index, orient='h')\n",
    "\n",
    "ax.set_title(\"Decision Tree: Feature Importances\", fontsize=20)\n",
    "\n",
    "ax.set_xlabel(\"Importance\")\n",
    "ax.set_ylabel(\"Feature\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpipeline = Pipeline(steps=[\n",
    "                        (\"preprocessor\", preprocessor),\n",
    "                        (\"randomforest\", RandomForestClassifier(random_state=0))\n",
    "                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred = rfpipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Classifier\\n\")\n",
    "print('Accuracy:', '%.3f' % accuracy_score(y_test, rfpred))\n",
    "print('Precision:', '%.3f' % precision_score(y_test, rfpred))\n",
    "print('Recall:', '%.3f' % recall_score(y_test, rfpred))\n",
    "print('F1 Score:', '%.3f' % f1_score(y_test, rfpred))\n",
    "print('AUC score:', '%3.f' % roc_auc_score(y_test, rfpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcm = confusion_matrix(y_test,rfpred)\n",
    "rfcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,rfpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=rfpipeline, X=X_test, y=y_test, ax=ax, display_labels=rfpipeline.classes_)\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=rfpipeline, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv = cross_validate(estimator=rfpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=kf, n_jobs=2, return_train_score=True)\n",
    "rfcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv2 = cross_val_score(estimator=rfpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=skf, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpipeline.named_steps.randomforest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'randomforest__criterion': ['gini', 'entropy', 'log_loss']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs = GridSearchCV(estimator=rfpipeline, param_grid=parameters, scoring=scoring, n_jobs=-1, cv=5, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfgs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'randomforest__n_estimators': stats.randint(50, 200),\n",
    "              'randomforest__max_depth' : stats.randint(2,10),\n",
    "              'randomforest__min_samples_split': stats.randint(2,5),\n",
    "              'randomforest__min_samples_leaf' : stats.randint(1,5)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randm = RandomizedSearchCV(estimator=rfpipeline, param_distributions = parameters, cv = 5, n_iter = 10, \n",
    "                           n_jobs=2, scoring=\"roc_auc\", refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(rf_randm.cv_results_)\n",
    "\n",
    "print(results.shape)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results[['param_randomforest__max_depth', 'param_randomforest__min_samples_leaf', \n",
    "         'param_randomforest__min_samples_split', 'param_randomforest__n_estimators',\n",
    "         'mean_test_score']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name, model_object):\n",
    "    '''\n",
    "    Accepts as arguments a model name (your choice - string) and\n",
    "    a fit GridSearchCV model object.\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean F1 score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(mean f1 score)\n",
    "    best_estimator_results = cv_results.iloc[cv_results['mean_test_score'].idxmax(), :]\n",
    "\n",
    "    # Extract accuracy, precision, recall, and f1 score from that row\n",
    "#     f1 = best_estimator_results.mean_test_f1\n",
    "#     recall = best_estimator_results.mean_test_recall\n",
    "#     precision = best_estimator_results.mean_test_precision\n",
    "#     accuracy = best_estimator_results.mean_test_accuracy\n",
    "    rocauc = best_estimator_results.mean_test_score\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "#                         'F1': f1,\n",
    "#                         'Recall': recall,\n",
    "#                         'Precision': precision,\n",
    "#                         'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : rocauc  \n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function on our model\n",
    "rf_result_table = make_results(\"Random Forest RCV\", rf_randm)\n",
    "\n",
    "rf_result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance (or Gini) graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rfpipeline.named_steps.randomforest.feature_importances_\n",
    "\n",
    "feature_importances = pd.Series(importances, index=X.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "feature_importances.sort_values(ascending=False).plot.bar(ax=ax, figsize=(10,5))\n",
    "\n",
    "ax.set_title(\"Random Forest Feature Importances\", size=20)\n",
    "ax.tick_params('x', rotation=45)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_df = pd.DataFrame(feature_importances, columns=[\"importances\"])\n",
    "# feature_importances_df = feature_importances_df.sort_values(by='importances')\n",
    "# feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# sns.barplot(data=feature_importances_df, x=feature_importances_df.importances, y=feature_importances_df.index, orient='h')\n",
    "\n",
    "# ax.set_title(\"Decision Tree: Feature Importances for Employee Leaving\", fontsize=15)\n",
    "\n",
    "# ax.set_xlabel(\"Importance\")\n",
    "# ax.set_ylabel(\"Feature\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "\n",
    "Permutation feature importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This is especially useful for non-linear or opaque estimators. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.\n",
    "\n",
    "`\n",
    "permutation_importance(estimator, X,  y, scoring=None, n_repeats=5,\n",
    "                                   n_jobs=None, random_state=None, sample_weight=None, max_samples=1.0)\n",
    "`\n",
    "\n",
    "We need to pass the model and the validation set to the permutation_importance function.\n",
    "\n",
    "The n_repeats parameter specifies the number of times the feature values are shuffled. More repetitions will give more accurate results, but will take longer to compute.\n",
    "\n",
    "The random_state parameter is used to set the random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = permutation_importance(estimator=rfpipeline, X=X_test, y=y_test, n_jobs=-1, \n",
    "                            scoring=\"roc_auc\", random_state=0, n_repeats=10)\n",
    "\n",
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = pm.importances_mean.argsort()\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), pm.importances_mean[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\n",
    "plt.title('Permutation Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcpipeline = Pipeline(steps=[\n",
    "                        (\"preprocessor\", preprocessor),\n",
    "                        (\"graboost\", GradientBoostingClassifier(random_state=0))\n",
    "                    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcpipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcpred = gbcpipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcpred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boost Tree Classifier\\n\")\n",
    "print('Accuracy:', '%.3f' % accuracy_score(y_test, gbcpred))\n",
    "print('Precision:', '%.3f' % precision_score(y_test, gbcpred))\n",
    "print('Recall:', '%.3f' % recall_score(y_test, gbcpred))\n",
    "print('F1 Score:', '%.3f' % f1_score(y_test, gbcpred))\n",
    "print('AUC score:', '%3.f' % roc_auc_score(y_test, gbcpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbccv = cross_validate(estimator=gbcpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=kf, n_jobs=2, \n",
    "                    return_train_score=False)\n",
    "gbccv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbccv[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbccv[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV (GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcpipeline.named_steps.graboost.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'graboost__learning_rate': stats.uniform(0,1),\n",
    "              'graboost__n_estimators': stats.randint(50,250),\n",
    "              'graboost__min_samples_split' : stats.uniform(0,1),\n",
    "              'graboost__min_samples_leaf' : stats.uniform(0,1),\n",
    "              'graboost__max_depth': np.arange(2,10),\n",
    "              \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_randm = RandomizedSearchCV(estimator=gbcpipeline, param_distributions = parameters, cv = 5, n_iter = 10, \n",
    "                           n_jobs=-1, scoring='roc_auc', refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbc_randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(gbc_randm.cv_results_)\n",
    "\n",
    "results.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results[['param_graboost__learning_rate','param_graboost__max_depth', 'param_graboost__min_samples_leaf',\n",
    "         'param_graboost__min_samples_split','param_graboost__n_estimators']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name, model_object):\n",
    "    '''\n",
    "    Accepts as arguments a model name (your choice - string) and\n",
    "    a fit GridSearchCV model object.\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean F1 score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(mean f1 score)\n",
    "    best_estimator_results = cv_results.iloc[cv_results['mean_test_score'].idxmax(), :]\n",
    "\n",
    "    # Extract accuracy, precision, recall, and f1 score from that row\n",
    "    #f1 = best_estimator_results.mean_test_f1\n",
    "    #recall = best_estimator_results.mean_test_recall\n",
    "    #precision = best_estimator_results.mean_test_precision\n",
    "    #accuracy = best_estimator_results.mean_test_accuracy\n",
    "    rocauc = best_estimator_results.mean_test_score\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "#                         'F1': f1,\n",
    "#                         'Recall': recall,\n",
    "#                         'Precision': precision,\n",
    "#                         'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : rocauc  \n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function on our model\n",
    "gbc_result_table = make_results(\"Gradient Boosting RCV\", gbc_randm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "\n",
    "Permutation feature importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This is especially useful for non-linear or opaque estimators. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature.\n",
    "\n",
    "`\n",
    "permutation_importance(estimator, X,  y, scoring=None, n_repeats=5,\n",
    "                                   n_jobs=None, random_state=None, sample_weight=None, max_samples=1.0)\n",
    "`\n",
    "\n",
    "We need to pass the model and the validation set to the permutation_importance function.\n",
    "\n",
    "The n_repeats parameter specifies the number of times the feature values are shuffled. More repetitions will give more accurate results, but will take longer to compute.\n",
    "\n",
    "The random_state parameter is used to set the random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbcpipeline = Pipeline(steps=[\n",
    "                        (\"preprocessor\", preprocessor),\n",
    "                        (\"graboost\", HistGradientBoostingClassifier(random_state=0))\n",
    "                    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;minmax&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;accountage&#x27;,\n",
       "                                                   &#x27;monthlycharges&#x27;,\n",
       "                                                   &#x27;totalcharges&#x27;,\n",
       "                                                   &#x27;viewinghoursperweek&#x27;,\n",
       "                                                   &#x27;averageviewingduration&#x27;,\n",
       "                                                   &#x27;contentdownloadspermonth&#x27;,\n",
       "                                                   &#x27;userrating&#x27;,\n",
       "                                                   &#x27;supportticketspermonth&#x27;,\n",
       "                                                   &#x27;watchlistsize&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;subscriptiontype&#x27;,\n",
       "                                                   &#x27;paymentmethod&#x27;,\n",
       "                                                   &#x27;paperlessbilling&#x27;,\n",
       "                                                   &#x27;contenttype&#x27;,\n",
       "                                                   &#x27;multideviceaccess&#x27;,\n",
       "                                                   &#x27;deviceregistered&#x27;,\n",
       "                                                   &#x27;genrepreference&#x27;, &#x27;gender&#x27;,\n",
       "                                                   &#x27;parentalcontrol&#x27;,\n",
       "                                                   &#x27;subtitlesenabled&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;graboost&#x27;, HistGradientBoostingClassifier(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;numerical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;minmax&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;accountage&#x27;,\n",
       "                                                   &#x27;monthlycharges&#x27;,\n",
       "                                                   &#x27;totalcharges&#x27;,\n",
       "                                                   &#x27;viewinghoursperweek&#x27;,\n",
       "                                                   &#x27;averageviewingduration&#x27;,\n",
       "                                                   &#x27;contentdownloadspermonth&#x27;,\n",
       "                                                   &#x27;userrating&#x27;,\n",
       "                                                   &#x27;supportticketspermonth&#x27;,\n",
       "                                                   &#x27;watchlistsize&#x27;]),\n",
       "                                                 (&#x27;categorical&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;subscriptiontype&#x27;,\n",
       "                                                   &#x27;paymentmethod&#x27;,\n",
       "                                                   &#x27;paperlessbilling&#x27;,\n",
       "                                                   &#x27;contenttype&#x27;,\n",
       "                                                   &#x27;multideviceaccess&#x27;,\n",
       "                                                   &#x27;deviceregistered&#x27;,\n",
       "                                                   &#x27;genrepreference&#x27;, &#x27;gender&#x27;,\n",
       "                                                   &#x27;parentalcontrol&#x27;,\n",
       "                                                   &#x27;subtitlesenabled&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;graboost&#x27;, HistGradientBoostingClassifier(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;minmax&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;accountage&#x27;, &#x27;monthlycharges&#x27;,\n",
       "                                  &#x27;totalcharges&#x27;, &#x27;viewinghoursperweek&#x27;,\n",
       "                                  &#x27;averageviewingduration&#x27;,\n",
       "                                  &#x27;contentdownloadspermonth&#x27;, &#x27;userrating&#x27;,\n",
       "                                  &#x27;supportticketspermonth&#x27;, &#x27;watchlistsize&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;subscriptiontype&#x27;, &#x27;paymentmethod&#x27;,\n",
       "                                  &#x27;paperlessbilling&#x27;, &#x27;contenttype&#x27;,\n",
       "                                  &#x27;multideviceaccess&#x27;, &#x27;deviceregistered&#x27;,\n",
       "                                  &#x27;genrepreference&#x27;, &#x27;gender&#x27;,\n",
       "                                  &#x27;parentalcontrol&#x27;, &#x27;subtitlesenabled&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;accountage&#x27;, &#x27;monthlycharges&#x27;, &#x27;totalcharges&#x27;, &#x27;viewinghoursperweek&#x27;, &#x27;averageviewingduration&#x27;, &#x27;contentdownloadspermonth&#x27;, &#x27;userrating&#x27;, &#x27;supportticketspermonth&#x27;, &#x27;watchlistsize&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;subscriptiontype&#x27;, &#x27;paymentmethod&#x27;, &#x27;paperlessbilling&#x27;, &#x27;contenttype&#x27;, &#x27;multideviceaccess&#x27;, &#x27;deviceregistered&#x27;, &#x27;genrepreference&#x27;, &#x27;gender&#x27;, &#x27;parentalcontrol&#x27;, &#x27;subtitlesenabled&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(steps=[('minmax',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['accountage',\n",
       "                                                   'monthlycharges',\n",
       "                                                   'totalcharges',\n",
       "                                                   'viewinghoursperweek',\n",
       "                                                   'averageviewingduration',\n",
       "                                                   'contentdownloadspermonth',\n",
       "                                                   'userrating',\n",
       "                                                   'supportticketspermonth',\n",
       "                                                   'watchlistsize']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['subscriptiontype',\n",
       "                                                   'paymentmethod',\n",
       "                                                   'paperlessbilling',\n",
       "                                                   'contenttype',\n",
       "                                                   'multideviceaccess',\n",
       "                                                   'deviceregistered',\n",
       "                                                   'genrepreference', 'gender',\n",
       "                                                   'parentalcontrol',\n",
       "                                                   'subtitlesenabled'])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('graboost', HistGradientBoostingClassifier(random_state=0))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgbcpipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_pred = hgbcpipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the second column of probabilities (class 1) and rename it\n",
    "hgbc_predicted_probability = hgbc_pred[:, 1]\n",
    "\n",
    "hgbcprob = hgbc_predicted_probability.round(0)\n",
    "\n",
    "hgbcprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Classifier\n",
      "\n",
      "Accuracy: 0.818\n",
      "Precision: 0.477\n",
      "Recall: 0.081\n",
      "F1 Score: 0.138\n",
      "AUC score:   1\n"
     ]
    }
   ],
   "source": [
    "print(\"HistGradientBoosting Classifier\\n\")\n",
    "print('Accuracy:', '%.3f' % accuracy_score(y_test, hgbcprob))\n",
    "print('Precision:', '%.3f' % precision_score(y_test, hgbcprob))\n",
    "print('Recall:', '%.3f' % recall_score(y_test, hgbcprob))\n",
    "print('F1 Score:', '%.3f' % f1_score(y_test, hgbcprob))\n",
    "print('AUC score:', '%3.f' % roc_auc_score(y_test, hgbcprob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.89036345, 0.65660357, 0.89549232, 0.94365668, 0.68397307]),\n",
       " 'score_time': array([0.05025244, 0.06183553, 0.07035041, 0.04222035, 0.03776002]),\n",
       " 'test_score': array([0.71192433, 0.7070294 , 0.71352827, 0.72270775, 0.73817637])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgcv = cross_validate(estimator=hgbcpipeline, X=X_train, y=y_train, scoring=\"roc_auc\", cv=skf, n_jobs=2)\n",
    "hgcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7186732212016643"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgcv[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc = HistGradientBoostingClassifier(early_stopping='auto', scoring='roc_auc', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'loss' : ('auto', 'binary_crossentropy', 'categorical_crossentropy'),\n",
    "              'learning_rate': np.arange(0.0,1.1,0.2),\n",
    "              'max_depth': np.arange(2,10,2),\n",
    "              'min_samples_leaf': np.arange(5,21,5),\n",
    "              'max_depth': np.arange(2,11,1)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a dictionary of scoring metrics to capture\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_randm = RandomizedSearchCV(estimator=hgbc, param_distributions = parameters, cv = 5, n_iter = 55, \n",
    "                           n_jobs=2, scoring=scoring, refit='roc_auc', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hgbc_randm.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(hgbc_randm.cv_results_)\n",
    "\n",
    "print(results.shape)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_roc_auc', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results[[\"param_loss\", \"param_max_depth\", \"param_min_samples_leaf\", \n",
    "         \"param_learning_rate\", \"mean_test_accuracy\", \"mean_test_recall\",\n",
    "         \"mean_test_precision\",\"mean_test_f1\",\"mean_test_roc_auc\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Hist Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbcm = confusion_matrix(y_test, hgbc_pred)\n",
    "hgbcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, hgbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=hgbcm, X=X_test, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=hgbcm, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a feature importance graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permimpt = permutation_importance(estimator=hgbc, X=X_train, y=y_train, scoring=\"roc_auc\", n_repeats=5,\n",
    "                       n_jobs=None, random_state=0)\n",
    "\n",
    "permimpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_importances = pd.Series(data=permimpt[\"importances_mean\"], index=X.columns)\n",
    "hgbc_sorted = hgbc_importances.sort_values(ascending=False)\n",
    "\n",
    "hgbc_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.barplot(hgbc_sorted.index, hgbc_sorted.values)\n",
    "\n",
    "ax.set_title(\"Hist Gradient Boosting Features Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probability = hgbcpipeline.predict_proba(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87631311, 0.12368689],\n",
       "       [0.95458174, 0.04541826],\n",
       "       [0.67042014, 0.32957986],\n",
       "       ...,\n",
       "       [0.91997823, 0.08002177],\n",
       "       [0.73354683, 0.26645317],\n",
       "       [0.97210522, 0.02789478]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probability = predicted_probability.round(0)[:,1]\n",
    "predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"testoriginal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountAge</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>SubscriptionType</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>MultiDeviceAccess</th>\n",
       "      <th>DeviceRegistered</th>\n",
       "      <th>ViewingHoursPerWeek</th>\n",
       "      <th>AverageViewingDuration</th>\n",
       "      <th>ContentDownloadsPerMonth</th>\n",
       "      <th>GenrePreference</th>\n",
       "      <th>UserRating</th>\n",
       "      <th>SupportTicketsPerMonth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>WatchlistSize</th>\n",
       "      <th>ParentalControl</th>\n",
       "      <th>SubtitlesEnabled</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>17.87</td>\n",
       "      <td>679.04</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>29.13</td>\n",
       "      <td>122.27</td>\n",
       "      <td>42</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>O1W6BHP6RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>9.91</td>\n",
       "      <td>763.29</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>36.87</td>\n",
       "      <td>57.09</td>\n",
       "      <td>43</td>\n",
       "      <td>Action</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>LFR4X92X8H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15.02</td>\n",
       "      <td>75.10</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Computer</td>\n",
       "      <td>7.60</td>\n",
       "      <td>140.41</td>\n",
       "      <td>14</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4.81</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>QM5GBIYODA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>15.36</td>\n",
       "      <td>1351.45</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>35.59</td>\n",
       "      <td>177.00</td>\n",
       "      <td>14</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4.94</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>D9RXTK2K9F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>12.41</td>\n",
       "      <td>1128.95</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>23.50</td>\n",
       "      <td>70.31</td>\n",
       "      <td>6</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>ENTCCHR1LR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountAge  MonthlyCharges  TotalCharges SubscriptionType     PaymentMethod PaperlessBilling ContentType MultiDeviceAccess DeviceRegistered  ViewingHoursPerWeek  AverageViewingDuration  ContentDownloadsPerMonth GenrePreference  UserRating  SupportTicketsPerMonth  Gender  WatchlistSize ParentalControl SubtitlesEnabled  CustomerID\n",
       "0          38           17.87        679.04          Premium      Mailed check               No    TV Shows                No               TV                29.13                  122.27                        42          Comedy        3.52                       2    Male             23              No               No  O1W6BHP6RM\n",
       "1          77            9.91        763.29            Basic  Electronic check              Yes    TV Shows                No               TV                36.87                   57.09                        43          Action        2.02                       2  Female             22             Yes               No  LFR4X92X8H\n",
       "2           5           15.02         75.10         Standard     Bank transfer               No    TV Shows               Yes         Computer                 7.60                  140.41                        14          Sci-Fi        4.81                       2  Female             22              No              Yes  QM5GBIYODA\n",
       "3          88           15.36       1351.45         Standard  Electronic check               No        Both               Yes           Tablet                35.59                  177.00                        14          Comedy        4.94                       0  Female             23             Yes              Yes  D9RXTK2K9F\n",
       "4          91           12.41       1128.95         Standard       Credit card              Yes    TV Shows               Yes           Tablet                23.50                   70.31                         6           Drama        2.85                       6  Female              0              No               No  ENTCCHR1LR"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions with label column into a dataframe\n",
    "prediction_df = pd.DataFrame({'CustomerID': test_df[['CustomerID']].values[:, 0],\n",
    "                             'predicted_probability': predicted_probability})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O1W6BHP6RM</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LFR4X92X8H</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QM5GBIYODA</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D9RXTK2K9F</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTCCHR1LR</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104475</th>\n",
       "      <td>UTKREC613O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104476</th>\n",
       "      <td>MDB4E477PS</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104477</th>\n",
       "      <td>IPDIA02ZE1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104478</th>\n",
       "      <td>ITLFTPRJGV</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104479</th>\n",
       "      <td>Y204GZY6NE</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CustomerID  predicted_probability\n",
       "0       O1W6BHP6RM                   0.00\n",
       "1       LFR4X92X8H                   0.00\n",
       "2       QM5GBIYODA                   0.00\n",
       "3       D9RXTK2K9F                   0.00\n",
       "4       ENTCCHR1LR                   0.00\n",
       "...            ...                    ...\n",
       "104475  UTKREC613O                   0.00\n",
       "104476  MDB4E477PS                   0.00\n",
       "104477  IPDIA02ZE1                   0.00\n",
       "104478  ITLFTPRJGV                   0.00\n",
       "104479  Y204GZY6NE                   0.00\n",
       "\n",
       "[104480 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "# Writing to csv for autograding purposes\n",
    "prediction_df.to_csv(\"prediction_submission.csv\", index=False)\n",
    "submission = pd.read_csv(\"prediction_submission.csv\")\n",
    "\n",
    "assert isinstance(submission, pd.DataFrame), 'You should have a dataframe named prediction_df.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.columns[0] == 'CustomerID', 'The first column name should be CustomerID.'\n",
    "assert submission.columns[1] == 'predicted_probability', 'The second column name should be predicted_probability.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.shape[0] == 104480, 'The dataframe prediction_df should have 104480 rows.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST CELLS - please make sure all of your code is above these test cells\n",
    "\n",
    "assert submission.shape[1] == 2, 'The dataframe prediction_df should have 2 columns.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (Scikit-Learn)\n",
    "\n",
    "XGBoost is a widespread implementation of gradient boosting. Let’s discuss some features of XGBoost that make it so attractive.\n",
    "\n",
    "- XGBoost offers regularization, which allows you to control overfitting by introducing L1/L2 penalties on the weights and biases of each tree. This feature is not available in many other implementations of gradient boosting.\n",
    "- Another feature of XGBoost is its ability to handle sparse data sets using the weighted quantile sketch algorithm. This algorithm allows us to deal with non-zero entries in the feature matrix while retaining the same computational complexity as other algorithms like stochastic gradient descent.\n",
    "- XGBoost also has a block structure for parallel learning. It makes it easy to scale up on multicore machines or clusters. It also uses cache awareness, which helps reduce memory usage when training models with large datasets.\n",
    "- Finally, XGBoost offers out-of-core computing capabilities using disk-based data structures instead of in-memory ones during the computation phase.\n",
    "\n",
    "\n",
    "<img src = \"treesalgo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validated hyperparameter tuning (GridSearchCV)\n",
    "\n",
    "The cross-validation process is the same as it was for the decision tree and random forest models. The only difference is that we're tuning different hyperparameters now. The steps are included below as a review. \n",
    "\n",
    "For details on cross-validating with `GridSearchCV`, refer back to the [decision tree notebook](https://colab.sandbox.google.com/drive/164Aa1ODOMSIY_5-ZP1PA5afGegTqqjcv?resourcekey=0-hZwiQ1rxwUAol5kaj7-o4w#tuning), or to the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) in scikit-learn.\n",
    "\n",
    "1. Instantiate the classifier (and set the `random_state`). Note here that we've included a parameter called `objective` whose value is `binary:logistic`. This means that the model is performing a binary classification task that outputs a logistic probability. The objective would be different for different kinds of problems—for instance, if you were trying to predict more than two classes or performing a linear regression on continuous data. Refer to the [XGBoost documentation](https://xgboost.readthedocs.io/en/stable/parameter.html) for more information.\n",
    "\n",
    "2. Create a dictionary of hyperparameters to search over.\n",
    "\n",
    "3. Create a dictionary of scoring metrics to capture. \n",
    "\n",
    "4. Instantiate the `GridSearchCV` object. Pass as arguments:\n",
    "  - The classifier (`xgb`)\n",
    "  - The dictionary of hyperparameters to search over (`cv_params`)\n",
    "  - The dictionary of scoring metrics (`scoring`)\n",
    "  - The number of cross-validation folds you want (`cv=5`)\n",
    "  - The scoring metric that you want GridSearch to use when it selects the \"best\" model (i.e., the model that performs best on average over all validation folds) (`refit='f1'`)\n",
    "\n",
    "5. Fit the data (`X_train`, `y_train`) to the `GridSearchCV` object (`xgb_cv`)\n",
    "\n",
    "Note that we use the `%%time` magic at the top of the cell where we fit the model. This outputs the final runtime of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbcgs = XGBClassifier(random_state=0, n_estimators=100, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': np.arange(2,10,2),\n",
    "              'learning_rate': np.arange(0.1,0.5,0.1),\n",
    "              'n_estimators':np.arange(50,350,50),\n",
    "              'min_child_weight': [1,2,3,4,5]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbgs = GridSearchCV(estimator=xgbc,param_grid=parameters,scoring=scoring,\n",
    "                     n_jobs=2, cv=5, verbose=1, refit='roc_auc', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgbgs.fit(X_random_train,y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name, model_object):\n",
    "    '''\n",
    "    Accepts as arguments a model name (your choice - string) and\n",
    "    a fit GridSearchCV model object.\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean F1 score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(mean f1 score)\n",
    "    best_estimator_results = cv_results.iloc[cv_results['mean_test_roc_auc'].idxmax(), :]\n",
    "\n",
    "    # Extract accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    rocauc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'F1': f1,\n",
    "                        'Recall': recall,\n",
    "                        'Precision': precision,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : rocauc  \n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xgb model results table\n",
    "xgb_cv_results = make_results('XGBoost GSCV', xgbgs)\n",
    "xgb_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbcrm = XGBClassifier(random_state=0, n_estimators=100, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbcrm = XGBClassifier(random_state=0, n_estimators=100, objective='softmax:multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': np.arange(2,11,1),\n",
    "              'eta': [0.01, 0.1, 0.5, 1.0],\n",
    "              'n_estimators': np.arange(50,300,50),\n",
    "              'min_child_weight': np.arange(1,4,1),\n",
    "              'gamma': np.arange(0,11,2),\n",
    "              'subsample': np.arange(0.1, 0.9, 0.1),\n",
    "              'colsample_bytree': np.arange(0.5,0.9,0.1),\n",
    "              'reg_alpha': np.arange(0.0 , 1.0, 0.2),\n",
    "              'reg_lambda': np.arange(0.0, 1.0, 0.2)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrandm = RandomizedSearchCV(estimator=xgbcrm, param_distributions = parameters, cv = 5, n_iter = 55, \n",
    "                           n_jobs=2, scoring=scoring, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrandm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbrandm.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrandm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrandm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrandm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Feature importance\n",
    "\n",
    "The XGBoost library has a function called `plot_importance`, which we imported at the beginning of this notebook. This let's us check the features selected by the model as the most predictive. We can create a plot by calling this function and passing to it the best estimator from our grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_importance(xgbrandm.best_estimator_, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(xgbmodel.feature_importances_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.nlargest(10).plot(kind='barh', figsize=(10,8))\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The permutation based importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(rf,X_test,y_test, random_state=0, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Permutation-based Importance\")\n",
    "plt.barh(X.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Importance from SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "\n",
    "Create a table of results to compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of results to compare model performance.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table = table.append({'Model': \"Tuned Decision Tree\",\n",
    "                        'F1':  0.945422,\n",
    "                        'Recall': 0.935863,\n",
    "                        'Precision': 0.955197,\n",
    "                        'Accuracy': 0.940864\n",
    "                      },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "\n",
    "table = table.append({'Model': \"Tuned Random Forest\",\n",
    "                        'F1':  0.947306,\n",
    "                        'Recall': 0.944501,\n",
    "                        'Precision': 0.950128,\n",
    "                        'Accuracy': 0.942450\n",
    "                      },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "\n",
    "table = table.append({'Model': \"Tuned XGBoost\",\n",
    "                        'F1':  f1_score,\n",
    "                        'Recall': rc_score,\n",
    "                        'Precision': pc_score,\n",
    "                        'Accuracy': ac_score\n",
    "                      },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "Feature selection is the process of choosing features to be used for modeling. In practice, feature selection takes place at multiple points in the PACE process. Although sometimes you will be given a dataset and a defined target variable, most often in practice you will begin with only a question or a problem that you are tasked with solving. In these cases, if you decide that the problem requires a model, you'll then have to:\n",
    "\n",
    "* Consider what data is available to you\n",
    "* Decide on what kind of model you need\n",
    "* Decide on a target variable\n",
    "* Assemble a collection of features that you think might help predict on your chosen target\n",
    "\n",
    "This would all take place during the **Plan** phase. \n",
    "\n",
    "Then, during the **Analyze** phase, you would perform EDA on the data and reevaluate your variables for appropriateness. For example, can your model handle null values? If not, what do you do with features with a lot of nulls? Perhaps you drop them. This too is feature selection.\n",
    "\n",
    "But it doesn't end there. Feature selection also occurs during the **Construct** phase. This usually involves building a model, examining which features are most predictive, and then removing the unpredictive features.\n",
    "\n",
    "There's a lot of work involved in feature selection. In our case, we already have a dataset, and we're not performing thorough EDA on it. But we can still examine the data to ensure that all the features can reasonably be expected to have predictive potential. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold (Numeric Only)\n",
    "\n",
    "Remember we should apply the variance filter only on numerical variables.\n",
    "\n",
    "Default Value of Threshold is 0\n",
    "\n",
    "    If Variance Threshold = 0 (Remove Constant Features )\n",
    "    If Variance Threshold > 0 (Remove Quasi-Constant Features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_n=0.95\n",
    "\n",
    "# vt = VarianceThreshold(threshold=(threshold_n* (1 - threshold_n) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vtfit = vt.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vtfit.variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vt.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vt.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant and Quasi-constant features with Feature-engine\n",
    "\n",
    "In this notebook, we will remove constant and quasi-constant features utilizing the new functionality from Feature-engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:17]\n",
    "y = df.iloc[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant features\n",
    "\n",
    "The DropConstantFeatures class from Feature-engine finds and removes constant and quasi-constant features from a dataset. We can remove constant features by setting the parameter tol to 1, or quasi-constant with smaller values for tol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = DropConstantFeatures(tol=1, variables=None, missing_values='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of constant features\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant features from the data\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = DropConstantFeatures(tol=0.90, variables=None, missing_values='raise') #90% majority observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of quasi-constant features\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of observations showing each of the different values\n",
    "# of the variable\n",
    "\n",
    "var = sel.features_to_drop_[0]\n",
    "\n",
    "X_train[var].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the quasi-constant features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated features with Feature-engine\n",
    "\n",
    "In this notebook, we will identify and remove duplicated features with Feature-engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the selector\n",
    "sel = DropDuplicateFeatures(variables=None, missing_values='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duplicate features, this might take a while\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the pairs of duplicated features\n",
    "# each set are duplicates\n",
    "\n",
    "sel.duplicated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the features that will be dropped\n",
    "# 1 from each of the pairs above\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicated features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Correlation)\n",
    "\n",
    "Correlation Feature Selection evaluates subsets of features on the basis of the following hypothesis: \"Good feature subsets contain features highly correlated with the target, yet uncorrelated to each other\".\n",
    "\n",
    "### Correlation with Feature-engine\n",
    "\n",
    "- The DropCorrelatedFeatures class from Feature-engine does a similar job to the brute force approach that we described earlier.\n",
    "\n",
    "- The SmartCorrelationSelection allows us to select a feature from each correlated group based on model performance, number of missing values, cardinality or variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the selector\n",
    "\n",
    "sel = DropCorrelatedFeatures(\n",
    "    threshold=0.8,\n",
    "    method='pearson',\n",
    "    missing_values='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find correlated features\n",
    "\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each set contains a group of correlated features\n",
    "\n",
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop correlated features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmartCorrelationSelection\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "We will keep a feature from each correlation group based on the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation selector\n",
    "sel = SmartCorrelatedSelection(\n",
    "    variables=None, # if none, selector examines all numerical variables\n",
    "    method=\"pearson\",\n",
    "    threshold=0.8,\n",
    "    missing_values=\"raise\",\n",
    "    selection_method=\"model_performance\",\n",
    "    estimator=lr,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may take a while, because we are training\n",
    "# a random forest per correlation group\n",
    "\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups of correlated features\n",
    "\n",
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this group, several features are highly correlated. Which one should we keep and which ones should we remove?**\n",
    "\n",
    "One criteria to select which features to use from this group, would be to use those with **less missing data**. \n",
    "\n",
    "Our dataset contains no missing values, so this is not an option. But keep this in mind when you work with your own datasets.\n",
    "\n",
    "**Note**\n",
    "\n",
    "None of the 2 procedures for removing correlated features are perfect, and some correlated features may escape the loops of code. So it might be worthwhile checking that after removing the correlated features, there are no correlated features left in the dataset. If there are, repeat the procedure to remove the remaining ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Statistical Tests)\n",
    "\n",
    "## Mutual information\n",
    "\n",
    "The mutual information measures the reduction in uncertainty in variable A when variable B is known. \n",
    "\n",
    "To select variables, we are interested in the mutual information between the predictor variables and the target. Higher mutual information values, indicate little uncertainty about the target Y given the predictor X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the mutual information\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "# and make a bar  plot\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending=False).plot.bar(figsize=(20,6))\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Mutual Information')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will select the top 10 features\n",
    "# based on their mutual information value\n",
    "\n",
    "# select features\n",
    "selkbest = SelectKBest(mutual_info_classif, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selkbest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display features\n",
    "X_train.columns[selkbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = selkbest.transform(X_train)\n",
    "X_test = selkbest.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape    # Can start training ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features in the top percentile\n",
    "selpercent = SelectPercentile(mutual_info_classif, percentile=30) # Based on no of features to decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selpercent.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the features\n",
    "X_train.columns[selpercent.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = selpercent.transform(X_train)\n",
    "X_test = selpercent.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). The methods estimate the degree of linear dependency between two random variables. In this case, any of the predictor variables and the target. \n",
    "\n",
    "ANOVA assumes a linear relationship between the feature and the target and that the variables follow a Gaussian distribution. If this is not true, the result of this test may not be useful.\n",
    "\n",
    "These may not always be the case for the variables in your dataset, so if looking to implement these procedure, you will need to corroborate these assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate anova\n",
    "univariate = f_classif(X_train, y_train)\n",
    "\n",
    "# plot values\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 10 features\n",
    "selkbest = SelectKBest(f_classif, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selkbest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display selected feature names\n",
    "X_train.columns[selkbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = selpercent.transform(X_train)\n",
    "X_test = selpercent.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features in top 10th percentile\n",
    "selpercent= SelectPercentile(f_classif, percentile=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selpercent.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display selected feature names\n",
    "X_train.columns[selpercent.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the rest of the features:\n",
    "\n",
    "X_train = selpercent.transform(X_train)\n",
    "X_test = selpercent.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Other Methods)\n",
    "\n",
    "## Univariate Performance with Feature-engine\n",
    "\n",
    "This procedure works as follows:\n",
    "\n",
    "- Train a ML model per every single feature\n",
    "- Determine the performance of the models\n",
    "- Select features if model performance is above a certain threshold\n",
    "\n",
    "The C value in Logistic Regression is an user adjustable parameter that controls regularisation. In simple terms, higher values of C will instruct our model to fit the training set as best as possible, while lower C values will favour a simple models with coefficients closer to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the machine learning model\n",
    "# lr = LogisticRegression(penalty='l2', C=1000, random_state=0, solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the selector\n",
    "sel = SelectBySingleFeaturePerformance(\n",
    "    variables=None,\n",
    "    estimator=gbc,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predictive features\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predictive features\n",
    "sel.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the transformer stores a dictionary of feature:metric pairs\n",
    "# notice that the roc can be positive or negative.\n",
    "# the selector selects based on the absolute value\n",
    "\n",
    "#In general, an AUC of 0.5 suggests no discrimination \n",
    "#(i.e., ability to diagnose patients with and without the disease or condition based on the test), \n",
    "#0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding\n",
    "\n",
    "sel.feature_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel.feature_performance_).sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.title('Performance of ML models trained with individual features', size=15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('ROC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plot but taking the absolute value of the r2\n",
    "\n",
    "# np.abs(pd.Series(sel.feature_performance_)).sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "# plt.title('Performance of ML models trained with individual features', size=15)\n",
    "# plt.ylabel('ROC Score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features that will be removed\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features in the dataframes\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step forward feature selection\n",
    "\n",
    "Step forward feature selection starts by training a machine learning model for each feature in the dataset and selecting, as the starting feature, the one that returns the best performing model according to the evaluation criteria we choose.\n",
    "\n",
    "In the second step, it creates machine learning models for all combinations of the feature selected in the previous step and a second feature. It selects the pair that produces the best performing algorithm.\n",
    "\n",
    "It continues by adding 1 feature at a time to the features that were selected in previous steps, until a stopping criteria is reached.\n",
    "\n",
    "In theory, models with more features perform better. The algorithm will continue adding new features until a certain criteria is met. For example, until the model performance does not increase beyond a certain threshold. Or, as we show in this notebook, until a certain number of features are selected.\n",
    "\n",
    "The model performance metric can be the roc_auc for classification and the r squared for regression, for example, and it is determined by the user. \n",
    "\n",
    "Step forward feature selection is called a greedy procedure because it evaluates many possible single, double, triple, and so on feature combinations. Therefore, it is very computationally expensive and, sometimes, if the feature space is big enough, even unfeasible.\n",
    "\n",
    "Scikit-learn provides various stopping criteria to stop the search:\n",
    "\n",
    "* when a certain number of features is reached (like MLXtend) (arbitrary)\n",
    "* if the performance does not increase beyond a certain threshold (ideal but expensive)\n",
    "* selects half of the features (arbitrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"carpricemod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:14]\n",
    "y = df.iloc[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "\n",
    "# 1) the algorithm we want to create, in this case RandomForests\n",
    "# (note that I use few trees to speed things up)\n",
    "\n",
    "# 2) the stopping criteria: see sklearn documentation for more details\n",
    "\n",
    "# 3) whether to perform step forward or step backward\n",
    "\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "\n",
    "# this is going to take a while, do not despair\n",
    "\n",
    "sfs = SFS(estimator=LinearRegression(), \n",
    "          n_features_to_select=6,\n",
    "          direction='forward',\n",
    "          scoring='r2',\n",
    "          cv=5,\n",
    "          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.n_features_to_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8]\n",
    "y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "\n",
    "# 1) the algorithm we want to create, in this case RandomForests\n",
    "# (note that I use few trees to speed things up)\n",
    "\n",
    "# 2) the stopping criteria: see sklearn documentation for more details\n",
    "\n",
    "# 3) whether to perform step forward or step backward\n",
    "\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "\n",
    "# this is going to take a while, do not despair\n",
    "\n",
    "sfs = SFS(estimator=LogisticRegression(random_state=0), \n",
    "          n_features_to_select=4,\n",
    "          direction='forward',\n",
    "          scoring='f1',\n",
    "          cv=5,\n",
    "          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step backward feature selection\n",
    "\n",
    "Step Backward Feature Selection starts by fitting a model using all the features in the data set and determining its performance. \n",
    "\n",
    "Then, it trains models on all possible combinations of all features, minus one, and removes the feature that returns the model with the lowest performance.\n",
    "\n",
    "In the third step, it trains models in all possible combinations of the features remaining from step 2, minus 1 feature, and removes the feature that produced the lowest performing model.\n",
    "\n",
    "The algorithm stops when a certain criteria determined by the user is met. This criteria could be that the model performance does not decrease beyond a certain threshold, or alternatively, as we show in this notebook, when we reach a certain number of selected features.\n",
    "\n",
    "The evaluation metric can be the roc_auc for classification or the r squared for regression, for example, and is determined by the user.\n",
    "\n",
    "Step Backward Feature Selection is called greedy because it evaluates all possible n, and then n-1 and n-2 and so on feature combinations. Therefore, it is very computationally expensive and sometimes, if the feature space is big enough, even unfeasible.\n",
    "\n",
    "Scikit-learn provides various stopping criteria to stop the search:\n",
    "\n",
    "* when a certain number of features is reached (like MLXtend) (arbitrary)\n",
    "* if the performance does not increase beyond a certain threshold (ideal but expensive)\n",
    "* selects half of the features (arbitrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:14]\n",
    "y = df.iloc[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "\n",
    "# 1) the algorithm we want to create, in this case RandomForests\n",
    "# (note that I use few trees to speed things up)\n",
    "\n",
    "# 2) the stopping criteria: see sklearn documentation for more details\n",
    "\n",
    "# 3) whether to perform step forward or step backward\n",
    "\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "\n",
    "# this is going to take a while, do not despair\n",
    "\n",
    "sfs = SFS(estimator=LinearRegression(), \n",
    "          n_features_to_select=6,\n",
    "          direction='backward',\n",
    "          scoring='r2',\n",
    "          cv=5,\n",
    "          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.n_features_to_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Backward Feature Selection Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8]\n",
    "y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# within the SFS we indicate:\n",
    "\n",
    "# 1) the algorithm we want to create, in this case RandomForests\n",
    "# (note that I use few trees to speed things up)\n",
    "\n",
    "# 2) the stopping criteria: see sklearn documentation for more details\n",
    "\n",
    "# 3) whether to perform step forward or step backward\n",
    "\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "\n",
    "# this is going to take a while, do not despair\n",
    "\n",
    "sfs = SFS(estimator=LogisticRegression(random_state=0), \n",
    "          n_features_to_select=4,\n",
    "          direction='backward',\n",
    "          scoring='f1',\n",
    "          cv=5,\n",
    "          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle  \n",
    "\n",
    "When models take a long time to fit, you don’t want to have to fit them more than once. If your kernel disconnects or you shut down the notebook and lose the cell’s output, you’ll have to refit the model, which can be frustrating and time-consuming. \n",
    "\n",
    "`pickle` is a tool that saves the fit model object to a specified location, then quickly reads it back in. It also allows you to use models that were fit somewhere else, without having to train them yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "This step will ***W***rite (i.e., save) the model, in ***B***inary (hence, `wb`), to the folder designated by the above path. In this case, the name of the file we're writing is `rf_cv_model.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.sav'\n",
    "dump(xgbnew,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we save the model, we'll never have to re-fit it when we run this notebook. Ideally, we could open the notebook, select \"Run all,\" and the cells would run successfully all the way to the end without any model retraining. \n",
    "\n",
    "For this to happen, we'll need to return to the cell where we defined our grid search and comment out the line where we fit the model. Otherwise, when we re-run the notebook, it would refit the model. \n",
    "\n",
    "Similarly, we'll also need to go back to where we saved the model as a pickle and comment out those lines.  \n",
    "\n",
    "Next, we'll add a new cell that reads in the saved model from the folder we already specified. For this, we'll use `rb` (read binary) and be sure to assign the model to the same variable name as we used above, `rf_cv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(open(filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
