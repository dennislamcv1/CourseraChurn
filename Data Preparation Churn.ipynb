{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Churn\n",
    "\n",
    "## This notebook is for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tasks\n",
    "\n",
    "### 1) Understand the shape of the data (Histograms, box plots, etc.)\n",
    "\n",
    "### 2) Data Cleaning \n",
    "\n",
    "### 3) Data Exploration\n",
    "\n",
    "### 4) Feature Engineering \n",
    "\n",
    "### 5) Data Preprocessing for Model\n",
    "\n",
    "### 6) Basic Model Building \n",
    "\n",
    "### 7) Model Tuning \n",
    "\n",
    "### 8) Ensemble Model Building \n",
    "\n",
    "### 9) Results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from numpy import count_nonzero, median, mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import squarify\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date, time\n",
    "\n",
    "\n",
    "#import os\n",
    "#import zipfile\n",
    "import scipy\n",
    "from scipy import stats\n",
    "#from scipy.stats.mstats import normaltest # D'Agostino K^2 Test\n",
    "#from scipy.stats import boxcox\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler, Binarizer\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "%matplotlib inline\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60 \n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', titlesize=9)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use Feature-Engine library\n",
    "import feature_engine\n",
    "\n",
    "from feature_engine.imputation import AddMissingIndicator, CategoricalImputer, DropMissingData, MeanMedianImputer\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, RandomSampleImputer\n",
    "\n",
    "from feature_engine.outliers import Winsorizer, ArbitraryOutlierCapper, OutlierTrimmer\n",
    "\n",
    "from feature_engine.encoding import CountFrequencyEncoder, DecisionTreeEncoder, MeanEncoder, OneHotEncoder\n",
    "from feature_engine.encoding import OrdinalEncoder, WoEEncoder, RareLabelEncoder, StringSimilarityEncoder\n",
    "\n",
    "from feature_engine.discretisation import EqualWidthDiscretiser, EqualFrequencyDiscretiser, ArbitraryDiscretiser\n",
    "from feature_engine.discretisation import DecisionTreeDiscretiser, EqualWidthDiscretiser\n",
    "\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "\n",
    "from feature_engine.creation import CyclicalFeatures, MathFeatures, RelativeFeatures\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = pd.read_csv(\"data_descriptions.csv\")\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quick Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "train.describe(include=[\"int\", \"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "train.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable\n",
    "\n",
    "train.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountAge</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>SubscriptionType</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>MultiDeviceAccess</th>\n",
       "      <th>DeviceRegistered</th>\n",
       "      <th>ViewingHoursPerWeek</th>\n",
       "      <th>AverageViewingDuration</th>\n",
       "      <th>ContentDownloadsPerMonth</th>\n",
       "      <th>GenrePreference</th>\n",
       "      <th>UserRating</th>\n",
       "      <th>SupportTicketsPerMonth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>WatchlistSize</th>\n",
       "      <th>ParentalControl</th>\n",
       "      <th>SubtitlesEnabled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>17.87</td>\n",
       "      <td>679.04</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>29.13</td>\n",
       "      <td>122.27</td>\n",
       "      <td>42</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>9.91</td>\n",
       "      <td>763.29</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>No</td>\n",
       "      <td>TV</td>\n",
       "      <td>36.87</td>\n",
       "      <td>57.09</td>\n",
       "      <td>43</td>\n",
       "      <td>Action</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15.02</td>\n",
       "      <td>75.10</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Bank transfer</td>\n",
       "      <td>No</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Computer</td>\n",
       "      <td>7.60</td>\n",
       "      <td>140.41</td>\n",
       "      <td>14</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4.81</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>15.36</td>\n",
       "      <td>1351.45</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>No</td>\n",
       "      <td>Both</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>35.59</td>\n",
       "      <td>177.00</td>\n",
       "      <td>14</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4.94</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>12.41</td>\n",
       "      <td>1128.95</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>TV Shows</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>23.50</td>\n",
       "      <td>70.31</td>\n",
       "      <td>6</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountAge  MonthlyCharges  TotalCharges SubscriptionType     PaymentMethod PaperlessBilling ContentType MultiDeviceAccess DeviceRegistered  ViewingHoursPerWeek  AverageViewingDuration  ContentDownloadsPerMonth GenrePreference  UserRating  SupportTicketsPerMonth  Gender  WatchlistSize ParentalControl SubtitlesEnabled\n",
       "0          38           17.87        679.04          Premium      Mailed check               No    TV Shows                No               TV                29.13                  122.27                        42          Comedy        3.52                       2    Male             23              No               No\n",
       "1          77            9.91        763.29            Basic  Electronic check              Yes    TV Shows                No               TV                36.87                   57.09                        43          Action        2.02                       2  Female             22             Yes               No\n",
       "2           5           15.02         75.10         Standard     Bank transfer               No    TV Shows               Yes         Computer                 7.60                  140.41                        14          Sci-Fi        4.81                       2  Female             22              No              Yes\n",
       "3          88           15.36       1351.45         Standard  Electronic check               No        Both               Yes           Tablet                35.59                  177.00                        14          Comedy        4.94                       0  Female             23             Yes              Yes\n",
       "4          91           12.41       1128.95         Standard       Credit card              Yes    TV Shows               Yes           Tablet                23.50                   70.31                         6           Drama        2.85                       6  Female              0              No               No"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "test.describe(include=[\"int\", \"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "test.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable\n",
    "\n",
    "# test.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine both dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you split the data set into three splits, what we get is the test data set. The three splits consist of training data set, validation data set and test data set. You train the model using the training data set and assess the model performance using the validation data set. You optimize the model performance using training and validation data set. Finally, you test the model generalization performance using the test data set. The test data set remains hidden during the model training and model performance evaluation stage. One can split the data into a 70:20:10 ratio. 10% of the data set can be set aside as test data for testing the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([train,test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full.to_csv(\"fulldata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.pivot_table(data=df, index=['default'], aggfunc='median')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop([\"id\",\"year\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(\"airfare.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciKit Learn Column Transformers and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train.select_dtypes([\"int\", \"float\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train.select_dtypes([\"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = ['accountage', 'monthlycharges', 'totalcharges', 'viewinghoursperweek', 'averageviewingduration',\n",
    "          'contentdownloadspermonth', 'userrating', 'supportticketspermonth', 'watchlistsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = ['subscriptiontype', 'paymentmethod', 'paperlessbilling', 'contenttype', 'multideviceaccess', 'deviceregistered',\n",
    " 'genrepreference', 'gender', 'parentalcontrol', 'subtitlesenabled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 0:19]\n",
    "y = train.iloc[:, 19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp = SimpleImputer()\n",
    "# ss = StandardScaler()\n",
    "# mm = MinMaxScaler()\n",
    "# ohe = OneHotEncoder(drop_last=True)\n",
    "# binary = Binarizer(threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You use the ColumnTransformer to transform each column set separately before combining them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values Imputation Methods\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan,\n",
    "                    strategy='mean',\n",
    "                    fill_value=None,\n",
    "                    add_indicator=False)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan,\n",
    "                    strategy='median',\n",
    "                    fill_value=None,\n",
    "                    add_indicator=False)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan,\n",
    "                    strategy='constant',\n",
    "                    fill_value=0,\n",
    "                    add_indicator=False)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan,\n",
    "                    strategy='most_frequent',\n",
    "                    fill_value=None,\n",
    "                    add_indicator=False)\n",
    "\n",
    "indicator = MissingIndicator(missing_values=np.nan, features='missing-only', error_on_new=True)\n",
    "indicator\n",
    "\n",
    "imp2 = SimpleImputer(missing_values=np.nan,\n",
    "                    strategy='most_frequent',\n",
    "                    fill_value=None,\n",
    "                    add_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values imputation using ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    \n",
    "          transformers= [\n",
    "     \n",
    "         (\n",
    "             'imputer', SimpleImputer(missing_values=np.nan, \n",
    "                                      strategy='most_frequent', add_indicator=True), ['RankSeason', 'RankPlayoffs','OOBP', 'OSLG']\n",
    "         )\n",
    "         \n",
    "         ],\n",
    "             remainder='passthrough',\n",
    "             verbose_feature_names_out=False\n",
    "         )\n",
    "\n",
    "ct.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAUTION**\n",
    "\n",
    "The ColumnTransformer is, in essence, just slicing the dataframe into the required feature subsets. The SimpleImputer then performs operations on the sliced dataframes. Finally, the dataframes are put back together for the final output.\n",
    "\n",
    "That means that the order of the columns is not the same as in the training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot / Ordinal encoding\n",
    "# With a tree-based model, try OrdinalEncoder instead of OneHotEncoder even for nominal (unordered) features\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    \n",
    "     transformers= [\n",
    "     \n",
    "     (\n",
    "         'ohe1', OneHotEncoder(drop_last_binary=True), catcols\n",
    "     ),  \n",
    "         \n",
    "     (\n",
    "         'ohe2', OneHotEncoder(top_categories=3), []\n",
    "     ),\n",
    "         \n",
    "     ( \n",
    "         'oe',  OrdinalEncoder(missing_values='ignore'), []\n",
    "     ),\n",
    "         \n",
    "     (   'binary', Binarizer(threshold=0),[]\n",
    "     \n",
    "     )\n",
    "         \n",
    "     ],\n",
    "      remainder='passthrough',\n",
    "      verbose_feature_names_out=False\n",
    "     )\n",
    "\n",
    "ct.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    \n",
    "     transformers= [\n",
    "     \n",
    "      (\n",
    "         'ss', \n",
    "         StandardScaler(),\n",
    "         []\n",
    "      ),    \n",
    "      ( \n",
    "          'mm',\n",
    "          MinMaxScaler(),\n",
    "          numcols\n",
    "      )\n",
    "         \n",
    "     ],\n",
    "      remainder='passthrough',\n",
    "      verbose_feature_names_out=False\n",
    "     )\n",
    "\n",
    "ct.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = ct.fit_transform(X,y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_new.copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the pipeline for multiple transformations of the same columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create pipelines for numerical and categorical features\n",
    "\n",
    "```\n",
    "pipe = Pipeline(steps, *, memory=None, verbose=False)\n",
    "\n",
    "We create the preprocessing pipelines for both numerical and categorical data\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpipeline = Pipeline(steps=\n",
    "                      [\n",
    "                      (\"imputer\", SimpleImputer()),\n",
    "                      (\"scaler\", StandardScaler()),\n",
    "                      (\"minmax\", MinMaxScaler())   \n",
    "                      ]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catpipeline = Pipeline(steps=\n",
    "                      [\n",
    "                      (\"imputer\", SimpleImputer()),    \n",
    "                      (\"ohe\", OneHotEncoder(drop_last_binary=True))    \n",
    "                      ]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    \n",
    "     transformers= [\n",
    "     \n",
    "     (\"numerical\", numpipeline, numcols ),    \n",
    "     (\"categorical\", catpipeline, catcols )\n",
    "         \n",
    "     ],\n",
    "      remainder='passthrough',\n",
    "      verbose_feature_names_out=True\n",
    "     )\n",
    "\n",
    "preprocessor.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a final pipeline to include transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalpipeline = Pipeline(steps=\n",
    "                       [\n",
    "                       (\"preprocessor\", preprocessor)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalpipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalpipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,50), layout=(len(df.columns),2), grid=False)\n",
    "plt.suptitle('Histogram Feature Distribution', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(20,10), color='blue', fontsize=15)\n",
    "plt.suptitle('BoxPlots Feature Distribution', x=0.5, y=1.02, ha='center', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"landsurfacecondition\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"foundationtype\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"rooftype\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"groundfloortype\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"position\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"planconfiguration\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked Histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.histplot(data=df, x=\"legalownershipstatus\", y=None, hue=\"damagegrade\", multiple='dodge', stat='count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"landsurfacecondition\", y=\"damagegrade\", hue=None, data=df, row=None, col=None,\n",
    "    col_wrap=None, estimator=\"mean\", ci=95, kind='swarm', height=5, aspect=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"label\", y=\"drivenkmdrives\", hue=None, data=df, estimator=\"mean\", ci=95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=horizontal_label,\n",
    "            y=first_dimension,\n",
    "            hue=second_dimension,\n",
    "            data=df.groupby([first_dimension, second_dimension]).size().to_frame(horizontal_label).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, \n",
    "             height=5, aspect=1, kind=\"reg\",\n",
    "             #x_vars=['extra','mtatax','tollsamount','improvementsurcharge'],\n",
    "             y_vars=[\"calories\"]\n",
    "            \n",
    "            )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.scatterplot(x=\"NumberChildrenAtHome\", y=\"YearlyIncome\", hue=\"BikeBuyer\", data=df, \n",
    "            size=\"Gender\", ci=95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"NumberChildrenAtHome\", y=\"YearlyIncome\", hue=\"BikeBuyer\", data=df, kind='scatter',\n",
    "            row=None, col=None, col_wrap=None, height=4, aspect=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.lineplot(x=\"NumberChildrenAtHome\", y=\"NumberCarsOwned\", hue=\"HomeOwnerFlag\", size=None, style=None, data=df,\n",
    "            estimator='mean', ci=95)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"CountryRegionName\", y=\"NumberCarsOwned\", hue=None, data=df, row=None, col=None,\n",
    "    col_wrap=None, estimator=\"mean\", ci=95, kind='strip', height=4, aspect=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(x=\"verifiedstatus\", y=None, hue=None, data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.violinplot(x=\"age\", y=None, hue=None, data=df, split=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.kdeplot(x=\"income\", y=None, shade=True, vertical=False, kernel=None, data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=None, y=None, data=None, hue=None, col=None, row=None, col_wrap=None,\n",
    "    height=5, aspect=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=None, y=None, data=None, kind='scatter', color=None, height=6, ratio=5, hue=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"landsurfacecondition\", y=\"damagegrade\", data=df, kind='hist', color=None, height=6, ratio=5, hue=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, row=None, col=\"damagegrade\", hue=None, col_wrap=None,  sharex=True,  sharey=True,\n",
    "              height=5, aspect=1)\n",
    "\n",
    "g.map(sns.histplot, \"countfloorspreeq\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=df, row=None, col=\"damagegrade\", hue=None, col_wrap=None,  sharex=True,  sharey=True,\n",
    "              height=5, aspect=1)\n",
    "\n",
    "g.map(sns.histplot, \"area\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "  * **Feature selection**\n",
    "    * Removing uninformative features\n",
    "  * **Feature extraction**\n",
    "    * Creating new features from existing features\n",
    "  * **Feature transformation**\n",
    "    * Modifying existing features to better suit our objectives\n",
    "    * Encoding of categorical features as dummies\n",
    " \n",
    "When modeling, best practice is to perform a rigorous examination of your data before beginning feature engineering and feature selection. This process is important. Not only does it help you understand your data, what it's telling you, and what it's _not_ telling you, but it also can give you clues that help you create new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unwanted features (Based on Domain Knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['zipcodestart', 'zipcodeend', 'neighborhoodstart', 'neighborhoodend'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"cyclistic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing features after performing selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['lotarea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"ameshousingmod.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns =  {'species_Bream': 'bream',\n",
    "                           'species_Rare': 'rare'\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns as needed\n",
    " \n",
    "df = df.rename(columns =  {'countryregionname': 'country',\n",
    "                          'homeownerflag': 'homeowner',\n",
    "                          'numbercarsowned': 'cars',\n",
    "                          'numberchildrenathome':'child',\n",
    "                          'avemonthspend': 'spend'\n",
    "                          })\n",
    "\n",
    "# Display all column names after the update\n",
    "### YOUR CODE HERE ### \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 3: Using a new list of column names\n",
    "\n",
    "# Creating a list of new columns\n",
    "df_cols = ['RankSeason', 'RankPlayoffs', 'OOBP', 'OSLG', \n",
    "           'MIRankSeason', 'MIRankPlayoffs', \n",
    "           'MIOOBP', 'MIOSLG', 'Team', 'League', 'Year', \n",
    "           'RS', 'RA', 'W', 'OBP', 'SLG', 'BA', 'Playoffs', 'G'\n",
    "          ]\n",
    "\n",
    "# printing the columns\n",
    "# before renaming\n",
    "print(df2.columns)\n",
    "\n",
    "# Renaming the columns\n",
    "df2.columns = df_cols\n",
    "\n",
    "# printing the columns\n",
    "# after renaming\n",
    "print(df2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all column headers in pandas data frame lower case\n",
    "\n",
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = map(str.lower, train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = map(str.lower, test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accountage', 'monthlycharges', 'totalcharges', 'subscriptiontype', 'paymentmethod', 'paperlessbilling', 'contenttype', 'multideviceaccess', 'deviceregistered', 'viewinghoursperweek', 'averageviewingduration', 'contentdownloadspermonth', 'genrepreference', 'userrating', 'supportticketspermonth', 'gender', 'watchlistsize', 'parentalcontrol', 'subtitlesenabled'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special character\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special character\n",
    "df.columns = df.columns.str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special character\n",
    "df.columns = df.columns.str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special character\n",
    "df.columns = df.columns.str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv(\"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'limitbal', 'gender', 'educ', 'marital', 'age', 'medianpay', 'medianbillamt', 'medianpayamt', 'default'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"creditcard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify duplicate rows\n",
    "duplicateRows = df[df.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"Pokemon.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "Label Encoding is a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label_encoder object knows how to understand word labels. \n",
    "\n",
    "`label_encoder = LabelEncoder()`\n",
    "\n",
    "Encode labels in column 'Country'. \n",
    "\n",
    "`df['Timely'] = label_encoder.fit_transform(df['Timely'])` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with the features we want to combine\n",
    "\n",
    "features = ['payamt1', 'payamt2', 'payamt3', 'payamt4', 'payamt5', 'payamt6'\n",
    "     \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with functions to apply for combinations\n",
    "\n",
    "math_func = [\"sum\", \"prod\", \"mean\", \"median\", \"std\", \"max\", \"min\", \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_func = [\"median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of new features\n",
    "\n",
    "new_feature_names = [\"sum_f\", \"prod_f\", \"mean_f\", \"median_f\", \"std_f\", \"max_f\", \"min_f\", \"count_f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_names = [\"medianpay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate feature combination with Feature-engine\n",
    "\n",
    "create = MathFeatures(\n",
    "    variables=features,\n",
    "    func=math_func,\n",
    "    new_variables_names=new_feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create = MathFeatures(variables=features, func=\"median\", new_variables_names=[\"medianpayamt\"], drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine features\n",
    "\n",
    "df2 = create.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(\"creditcard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Features Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PolynomialFeatures(degree=2)\n",
    "x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = pr.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
